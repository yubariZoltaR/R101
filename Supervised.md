##  Supervised Learning(ì§€ë„í•™ìŠµ)

Standardization : (data - avg) / s.d
MinMax Scale = (data - min(data)) / (max(data) - min(data)) : 0~1 ì‚¬ì´ë¡œ ë°ì´í„°ë¥¼ ìœ„ì¹˜ì‹œí‚´

ëª¨í˜•í‰ê°€ê°œë… 
![image](https://user-images.githubusercontent.com/80673078/111432382-4cbc5600-8740-11eb-96b6-5dfbe666e963.png)

ROC curve (xì¶•ì— false positive rate, yì¶•ì— ë¯¼ê°ë„) : ê³¡ì„  ì•„ë˜ì˜ ë©´ì (AUC)ê°€ ë„“ì„ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸ì´ë©° 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ë‹¤. 
MSE(Mean Squared Error) 

Overfitting, Underfitting

Cross-Validation : ë°ì´í„°ë¥¼ trainìš©ê³¼ testìš©ìœ¼ë¡œ ë¶„ë¦¬í•œ ì´í›„ ì •í™•ë„ ì¸¡ì •ì— test ë°ì´í„° ì‚¬ìš© (ì¢…ë¥˜ëŠ” ë‹¤ì–‘)


#### 1\. k-nearest neighbor
ê°€ì¥ ê°€ê¹Œì´ ìˆëŠ” ë°ì´í„°ì— ì†í•œë‹¤ê³  ë³´ëŠ” ë°©ë²•

kappaí†µê³„ëŸ‰ : (ê´€ì¸¡ëœ ì •í™•ë„ - ê¸°ëŒ€ ì •í™•ë„) / (1 - ê¸°ëŒ€ ì •í™•ë„) -1ê³¼ 1ì‚¬ì´ì´ë©° 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ë‹¤.

``` r
install.packages("caret", dependencies = TRUE)
library(caret)
rawdata <- read.csv("data.csv", header= TRUE)
rawdata$Class <- as.factor(rawdata$Class)
str(rawdata)

analdata <- rawdata
set.seed(2021)                        # ê°™ì€ ê²°ê³¼ ë„ì¶œí•˜ë„ë¡ íŠ¹ì • ìˆ«ì ì§€ì •. 
datatotal <- sort(sample(nrow(analdata), nrow(analdata)*0.7)) 
# 7:3ìœ¼ë¡œ train, test ë°ì´í„° ë¶„ë¦¬, sortëŠ” ê²°ê³¼ í¸ì˜ë¥¼ ìœ„í•œ ì˜¤ë¦„ì°¨ìˆœ ì •ë¦¬, nrowëŠ” ë°ì´í„°í–‰ìˆ˜, sample(a,b)ëŠ” 1ë¶€í„° aê¹Œì§€ ìˆ«ìì¤‘ bì¶”ì¶œ
train <- rawdata[datatotal,]
test <- rawdata[-datatotal,]
train_x <- train[,1:13]
train_y <- train[,14]
test_x <- test[,1:13]
test_y <- test[,14]

ctrl <- trainControl(
          method = "repeatedcv",      # cross-validation ë°˜ë³µ
          number = 10,                # í›ˆë ¨ ë°ì´í„° fold ê°œìˆ˜
          repeats = 5                 # cvë°˜ë³µ íšŸìˆ˜
) 
customGrid <- expand.grid(k=1:10)     # ë²¡í„°, ì¸ì ì¡°í•©ì¸ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±
knnFit <- train(Class~.,              # íƒ€ê²Ÿ
                data = train,
                method = "knn",                     # ì‚¬ìš©í•  ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²•
                trControl = trainControl(),         # í•™ìŠµ ë°©ë²•
                preProcess = c("center", "scale"),  # í‘œì¤€í™”
                tuneGrid = expand.grid(k=1:10)      # íŠœë‹ íŒŒë¼ë¯¸í„° ê°’ ëª©ë¡
                metric = "Accuracy")                # ëª¨í˜• í‰ê°€ ë°©ì‹
knnFit
plot(knnFit)

pred_test <- predict(knnFit, newdata=test) #testë°ì´í„°ë¥¼ ì˜ ì˜ˆì¸¡í•˜ëŠ”ì§€
confusionMatrix(pred_test, test$Class)

importance_knn <- varImp(knnFit, scale = FALSE) #ë³€ìˆ˜ ì¤‘ìš”ë„
plot(importance_knn)
``` 

#### 2\. Logistic Regression
ì„ í˜•íšŒê·€ë¶„ì„ì´ ì¢…ì†ë³€ìˆ˜ê°€ ì—°ì†í˜•ë§Œ ê°€ëŠ¥í•˜ë©° ë¬´ì œí•œë²”ìœ„ë¥¼ ê°–ì§€ë§Œ, ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ì€ ë²”ì£¼í˜•, ì—°ì†í˜• ëª¨ë‘ ê°€ëŠ¥í•˜ë‚˜ ë²”ìœ„ëŠ” ì œí•œì´ ìˆë‹¤.   
z=Î±+ğ›½ğ‘¥ ì—ì„œ zì— ì œí•œì´ ìˆë„ë¡ í•˜ê¸° ìœ„í•´ì„œ logâ¡(ğ‘¦/(1âˆ’ğ‘¦))=ğ›¼+ğ›½ğ‘¥ í˜•íƒœë¡œ ë³€í˜•.   
ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ train methodì—ëŠ”    
Boosted Logistic Regression : method = "LogitBoost" ê°€ì¥ ê°„ë‹¨í•œ ëª¨í˜•ì—ì„œ ì‹œì‘í•´ ì—¬ëŸ¬ í”¼ì³ë¥¼ ë”í•˜ëŠ” ë°©ì‹   
Logistic Model Trees : method = "LMT" ì˜ì‚¬ê²°ì •ë‚˜ë¬´ì™€ ê²°í•©ëœ ëª¨í˜•   
Penalized Logistic Regression : method = "plr" ì •ê·œí™”ë¥¼ ë‘ì–´ì„œ ëª¨ë¸ì˜ ë³µì¡ì„±ì„ ì¡°ì ˆí•¨ìœ¼ë¡œì¨ ì˜¤ë²„í”¼íŒ… íšŒí”¼ (ğœ†ì˜ í¬ê¸°ì— ë”°ë¼ ë² íƒ€ê°’ì˜ ì˜ì—­ ë‹¬ë¼ì§)   
Regularized Logistic Regression : method = "regLogistic"    

``` r
rawdata2 <- read.csv("data2.csv", header= TRUE)
str(rawdata2)
rawdata2$target <- as.factor(rawdata2$target)
# ì´í•˜ ì—°ì†í˜• ë…ë¦½ë³€ìˆ˜ í‘œì¤€í™”
rawdata$age <- scale(rawdata$age)
rawdata$trestbps <- scale(rawdata$trestbps)
rawdata$chol <- scale(rawdata$chol)
rawdata$thalach <- scale(rawdata$thalach)
rawdata$oldpeak <- scale(rawdata$oldpeak)
rawdata$slope <- scale(rawdata$slope)
# ì´í•˜ ë²”ì£¼í˜• ë…ë¦½ë³€ìˆ˜ í‘œì¤€í™”
newdata <- rawdata
factorVar <- c("sex", "cp", "fbs", "restecg", "exang", "ca", "thal")
newdata[ ,factorVar] = lapply(newdata[ ,factorVar], factor)

set.seed(2021)                        
datatotal <- sort(sample(nrow(newdata), nrow(newdata)*0.7)) 
train <- rawdata[datatotal,]
test <- rawdata[-datatotal,]
train_x <- train[,1:13]
train_y <- train[,14]
test_x <- test[,1:13]
test_y <- test[,14]

ctrl <- trainControl(method = "repeatedcv", repeats=5)
logitFit <- train(target~.,
                  data=train,
                  method = "LogitBoost",
                  trControl = ctrl,
                  metric = "Accuracy")
logitFit
plot(logitFit)

pred_test <- predict(logitFit, newdata=test)
confusionMatrix(pred_test, test$target)

importance_logit <- varImp(logitFit, scale =FALSE)
plot(importance_logit)



